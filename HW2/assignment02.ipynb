{"cells":[{"cell_type":"markdown","metadata":{"id":"DSpX-A6FErvi"},"source":["## CS345 Fall 2022 Assignment 2\n"]},{"cell_type":"markdown","metadata":{"id":"vHsotxKfErvp"},"source":["### Preliminaries\n","\n","We'll start with a review of the notation used to represent a dataset. In supervised learning we work with a dataset of $N$ labeled examples: $\\mathcal{D} = \\{ (\\mathbf{x}_i, y_i) \\}_{i=1}^N$, where $\\mathbf{x}_i$ is a $d$-dimensional vector (we always use boldface to denote vectors), and $y_i$ is the label associated with $\\mathbf{x}_i$.  For the perceptron algorithm we used the labels $\\pm 1$, so make sure that is the case for the data you read in.\n","\n","Datasets:\n","\n","* The [Gisette](http://archive.ics.uci.edu/ml/datasets/Gisette) handwritten digit recognition dataset. For this dataset use the separately provided validation set for testing your classifiers.\n","* The [QSAR](http://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation) data for predicting the biochemical activity of a molecule.\n","* The [heart disease diagnosis](http://archive.ics.uci.edu/ml/datasets/Heart+Disease) dataset.\n","* The [Wisconsin breast cancer wisconsin dataset](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer).\n","* For developing your code, you can use one of the scikit-learn datasets, such as the [make_classification](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html#sklearn.datasets.make_classification) toy dataset generator.\n","  "]},{"cell_type":"markdown","metadata":{"id":"NX4nbwVOErvr"},"source":["## Part 1:  Variation on the perceptron algorithm \n","\n","In this part of the assignment you will work with the perceptron and an additional variant we will call the **ensemble perceptron**.\n","It is created by averaging the votes of multiple perceptron models to create a prediction.\n","Ensemble learning is a common theme in machine learning, and later in the semester we will see algorithms specifically designed for this purpose.  In this assignment we will create a very simple implementation of this idea.\n","The idea leverages a phenomenon known as [the wisdom of the crowd](https://en.wikipedia.org/wiki/Wisdom_of_the_crowd), namely that a collection of predictions of diverse experts (or even non experts), can, when aggregated lead to incredibly accurate predictions.\n","\n","\n","**The idea:**  Rather than using a single classifier for making a prediction, use an average of the predictions made by multiple perceptrons trained on the same dataset.  This can lead to more robust and accurate predictions.\n","\n","Here are the details of the training algorithm:\n","\n","**Ensemble perceptron**\n","\n","**Input:** number of perceptrons in the ensemble (`num_classifiers`).\n","\n","**Output:**  a list of perceptron classifiers.\n","\n","**Training:**\n","* Train `num_classifiers` perceptrons, each with a different initial weight vector (this is important!!!).  Each perceptron will be trained until convergence, or until a fixed number of epochs has passed (recall that an epoch is a loop over all the training data).\n","\n","**prediction:**\n","\n","* **decision_function:** Let $f_i(\\mathbf{x})$ be the decision function of perceptron $i$.  Then the decision function of the ensemble is defined as \n","\n","$$\n","f(\\mathbf{x}) = \\frac{1}{\\mathrm{num\\_classifiers}} \\sum_{i=1}^{\\mathrm{num\\_classifiers}} f_i(\\mathbf{x})\n","$$\n","\n","* **predict:**  The predict function will return $\\mathrm{sign}(f(\\mathbf{x}))$ where $f(\\mathbf{x})$ is the value of the decision function defined above.\n","\n","\n","\n","Here's what you need to do:\n","\n","- Implement the ensemble perceptron as a Python class called `ensemble_perceptron` using the same interface used in the code provided for the perceptron algorithm, i.e. provides the same methods with the same signature.  In each case make sure that your implementation **includes a bias term as described in the perceptron notebook** where you will find guidance on how to add a bias term to an algorithm that is expressed without one.\n","\n","- Compare the performance of the ensemble perceptron with the regular perceptron on the QSAR and breast cancer diagnosis datasets. Do so by estimating the accuracy on a sample of the data that you reserve for testing (the test set).  In each case reserve  70% of the data for training, and 30% for testing.  To gain more confidence in our error estimates, repeat this experiment using 10 random splits of the data into training/test sets for each algorithm.  It is best to use the same train-test splits for each algorithm.  Report the average accuracy and its standard deviation in a nicely formatted table.  Is there a version of the perceptron that appears to perform better?   (In answering this, consider the differences in performance you observe in comparison to the standard deviation).  Make sure to let the algorithm run for a sufficient number of epochs.\n","\n","A note about the classifier API:  in this course we follow the scikit-learn classifier API, which requires that a classifier have the following methods (in addition to a constructor):\n","\n","* `fit(X, y)`:  trains a classifier using a feature matrix `X` and a labels vector `y`.\n","* `predict(X)`:  given a feature matrix `X`, return a vector of labels for each feature vector represented by `X`.\n","\n","For those interested in more information about the scikit-learn API, here's a [link](https://scikit-learn.org/stable/developers/develop.html).\n"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","\n","%matplotlib inline"],"metadata":{"id":"pyp8ZqsqMmVF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#regular perceptron \n","class perceptron :\n","    \"\"\"An implementation of the perceptron algorithm.\n","    Note that this implementation does not include a bias term\"\"\"\n"," \n","    def __init__(self, iterations=100, learning_rate=0.2, \n","                 plot_data=False, random_w=True, seed=42) :\n","        self.iterations = iterations\n","        self.learning_rate = learning_rate\n","        self.plot_data = plot_data\n","        self.random_w = True\n","        self.seed = seed\n","  \n","    def fit(self, X, y) :\n","        \"\"\"\n","        Train a classifier using the perceptron training algorithm.\n","        After training the attribute 'w' will contain the perceptron weight vector.\n"," \n","        Parameters\n","        ----------\n"," \n","        X : ndarray, shape (num_examples, n_features)\n","        Training data.\n"," \n","        y : ndarray, shape (n_examples,)\n","        Array of labels.\n"," \n","        \"\"\"\n","        \n","        if self.random_w :\n","            rng = np.random.default_rng(self.seed)\n","            self.w = rng.uniform(-1 , 1, len(X[0]))\n","            # print(\"initialized with random weight vector\")\n","        else :\n","            self.w = np.zeros(len(X[0]))\n","            print(\"initialized with a zeros weight vector\")\n","        self.wold = self.w\n","        converged = False\n","        iteration = 0\n","        while (not converged and iteration <= self.iterations) :\n","            converged = True\n","            for i in range(len(X)) :\n","                if y[i] * self.decision_function(X[i]) <= 0 :\n","                    self.wold = self.w\n","                    self.w = self.w + y[i] * self.learning_rate * X[i]\n","                    converged = False\n","                    if self.plot_data:\n","                        self.plot_update(X, y, i)\n","            iteration += 1\n","        self.converged = converged\n","        if converged :\n","            print ('converged in %d iterations ' % iteration)\n"," \n","    def decision_function(self, x) :\n","        return np.dot(x, self.w)\n"," \n","    def predict(self, X) :\n","        \"\"\"\n","        make predictions using a trained linear classifier\n"," \n","        Parameters\n","        ----------\n"," \n","        X : ndarray, shape (num_examples, n_features)\n","        Training data.\n","        \"\"\"\n"," \n","        scores = np.dot(X, self.w)\n","        return np.sign(scores)\n","    \n","    def plot_update(self, X, y, ipt) :\n","        fig = plt.figure(figsize=(4,4))\n","        plt.xlim(-1,1)\n","        plt.ylim(-1,1)\n","        plt.xlabel(\"Feature 1\")\n","        plt.ylabel(\"Feature 2\")\n","        plt.arrow(0,0,self.w[0],self.w[1], \n","                  width=0.001,head_width=0.05, \n","                  length_includes_head=True, alpha=1,\n","                  linestyle='-',color='darkred')\n","        plt.arrow(0,0,self.wold[0],self.wold[1], \n","                  width=0.001,head_width=0.05, \n","                  length_includes_head=True, alpha=1,\n","                  linestyle='-',color='orange')\n","        anew = -self.w[0]/self.w[1]\n","        aold = -self.wold[0]/self.wold[1]\n","        pts = np.linspace(-1,1)\n","        plt.plot(pts, anew*pts, color='darkred')\n","        plt.plot(pts, aold*pts, color='orange')\n","        plt.title(\"in orange:  old w; in red:  new w\")\n","        cols = {1: 'g', -1: 'b'}\n","        for i in range(len(X)): \n","            plt.plot(X[i][0], X[i][1], cols[y[i]]+'o', alpha=0.6,markersize=5) \n","        plt.plot(X[ipt][0], X[ipt][1], 'ro', alpha=0.2,markersize=20)"],"metadata":{"id":"3gvE6lNyN9jL"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FayZVKloErvv"},"outputs":[],"source":["class ensemble_perceptron :\n","    def __init__(self, num_classifiers=50,\n","                 iterations=100, \n","                 learning_rate=0.2) :\n","                 \n","        self.num_classifiers = num_classifiers\n","        self.iterations = iterations\n","        self.learning_rate = learning_rate\n","        self.plot_data = False\n","        self.random_w = True\n","        self.seed = 42\n","        self.random_w = True\n","\n","    def fit(self,X,y):\n","\n","        if self.random_w :\n","            rng = np.random.default_rng(self.seed)\n","            self.w = rng.uniform(-1 , 1, (self.num_classifiers,len(X[0])+1))\n","            # print(\"initialized with random weight vector\")\n","        else :\n","            self.w = np.zeros(len(X[0]))\n","            print(\"initialized with a zeros weight vector\")\n","        self.wold = self.w\n","        converged = False\n","        iteration = 0\n","    # Each with a different initial weight vector (this is important!!!).\n","      #  if self.random_w :\n","      #    rng = np.random.default_rng(self.seed)\n","       \n","      #   self.w = rng.uniform(-1,1,(self.num_classifiers,len(X[0]+1)))\n","      #   print(\"Initial with different weight vector\")\n","      #   self.word = self.w \n","      #   converged = False\n","      #   iteration = 0\n","        while (not converged and iteration <= self.iterations):\n","          converged = True \n","          for i in range(len(X)) :\n","                if y[i] * self.decision_function_ensemble(X[i]) <= 0 :\n","                    self.wold = self.w\n","                    for j in range(self.num_classifiers):\n","                        self.w[j][1:] = self.w[j][1:] + y[i] * self.learning_rate * X[i]\n","                    # baise\n","                        self.w[j][0] = self.w[j][0] + y[i] * self.learning_rate \n","                        converged = False\n","                    if self.plot_data:\n","                        self.plot_update(X, y, i)\n","          iteration += 1\n","        self.converged = converged\n","        if converged :\n","            print ('converged in %d iterations ' % iteration)\n","\n","    def decision_function_single(self,id, x):\n","        return np.dot(x,self.w[id][1:]) + self.w[id][0]\n","\n","    def decision_function_ensemble(self, x):\n","        result = []\n","        for i in range (self.num_classifiers):\n","          result.append(self.decision_function_single(i,x))\n","        result = np.array(result)\n","        mean = np.mean(result)\n","\n","        return mean\n","\n","    \n","    def predict(self,X):\n","        final_score = []\n","        for i in range(len(X)):\n","          score = []\n","          for j in range (self.num_classifiers):\n","            score.append(np.dot(X[i],self.w[j][1:])+self.w[j][0])\n","          scores = np.mean(score)\n","          final_score.append(scores)\n","\n","        # scores = np.dot(X, self.w[1:]) +self.w[0]\n","        return np.sign(final_score)\n","    \n","    def plot_update(self, X, y, ipt) :\n","        fig = plt.figure(figsize=(4,4))\n","        plt.xlim(-1,1)\n","        plt.ylim(-1,1)\n","        plt.xlabel(\"Feature 1\")\n","        plt.ylabel(\"Feature 2\")\n","        plt.arrow(0,0,self.w[0],self.w[1], \n","                  width=0.001,head_width=0.05, \n","                  length_includes_head=True, alpha=1,\n","                  linestyle='-',color='darkred')\n","        plt.arrow(0,0,self.wold[0],self.wold[1], \n","                  width=0.001,head_width=0.05, \n","                  length_includes_head=True, alpha=1,\n","                  linestyle='-',color='orange')\n","        anew = -self.w[0]/self.w[1]\n","        aold = -self.wold[0]/self.wold[1]\n","        pts = np.linspace(-1,1)\n","        plt.plot(pts, anew*pts, color='darkred')\n","        plt.plot(pts, aold*pts, color='orange')\n","        plt.title(\"in orange:  old w; in red:  new w\")\n","        cols = {1: 'g', -1: 'b'}\n","        for i in range(len(X)): \n","            plt.plot(X[i][0], X[i][1], cols[y[i]]+'o', alpha=0.6,markersize=5) \n","        plt.plot(X[ipt][0], X[ipt][1], 'ro', alpha=0.2,markersize=20)\n","      \n","    "]},{"cell_type":"code","source":["# import QSAR dataset\n","QSAR_data = pd.read_csv('biodeg.csv',sep =\";\", header = None)\n","X_QSAR = QSAR_data.values[:,:-1]\n","y1 = QSAR_data.values[:,-1]\n","unique_label = np.unique(QSAR_data.values[:,-1])\n","y_QSAR = np.array([np.where(i== unique_label)[0][0]for i in y1])\n","print (\"------------\", y_QSAR)\n","y_QSAR = y_QSAR*2 -1\n","print (X_QSAR.shape, y_QSAR.shape)\n","print (y_QSAR)\n","\n","\n","# import breast cancer dataset\n","from sklearn.datasets import load_breast_cancer\n","breast_data = load_breast_cancer()\n","X_breast = breast_data.data\n","y_breast = breast_data.target\n","y_breast = y_breast * 2 - 1\n","print (X_breast.shape, y_breast.shape)\n","\n","\n","\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7Puw2_xUfMo","executionInfo":{"status":"ok","timestamp":1665508779987,"user_tz":360,"elapsed":830,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"outputId":"3e3b417a-9124-4f14-d03e-ea3f770b88cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["------------ [1 1 1 ... 0 0 0]\n","(1055, 41) (1055,)\n","[ 1  1  1 ... -1 -1 -1]\n","(569, 30) (569,)\n"]}]},{"cell_type":"code","source":["#compare ensemble perceptron with the regular perceptron on the QSAR and breast cancer diagnosis datasets\n","from sklearn.model_selection import train_test_split\n","accuracy_test_breast1= []\n","accuracy_test_QSAR1= []\n","\n","for l in range(10):\n","  X_train_breast, X_test_breast, y_train_breast, y_test_breast = train_test_split(\n","    X_breast, y_breast, test_size=0.3, random_state=l)\n","  X_train_QSAR, X_test_QSAR, y_train_QSAR, y_test_QSAR = train_test_split(\n","    X_QSAR, y_QSAR, test_size=0.3, random_state=l)\n","  p1 = ensemble_perceptron (num_classifiers=50,iterations=10, learning_rate=0.2)\n","  p1.fit(X_train_breast,y_train_breast)\n","  y_pred_test_breast = p1.predict(X_test_breast)\n","  p2 = ensemble_perceptron (num_classifiers=50,iterations=10, learning_rate=0.2)\n","  \n","  p2.fit(X_QSAR,y_QSAR)\n","  y_pred_test_QSAR = p2.predict(X_test_QSAR)\n","  accuracy_test_breast1.append(np.mean(y_test_breast == y_pred_test_breast))\n","  accuracy_test_QSAR1.append(np.mean(y_test_QSAR == y_pred_test_QSAR))\n","\n","\n","\n","print('accuracy for breast(test): ', accuracy_test_breast1)\n","print('accuracy for QSAR(test): ', accuracy_test_QSAR1)\n","\n","mean_breast1 = np.mean(accuracy_test_breast1)\n","st_d_breast1 = np.std(accuracy_test_breast1)\n","mean_QSAR1 = np.mean(accuracy_test_QSAR1)\n","st_d_QSAR1 = np.std(accuracy_test_QSAR1)\n","print(\"ensemble perceptron---------------------------------------------------\")\n","print(\"mean_breast\", mean_breast1, \" standardar deviation\", st_d_breast1)\n","print(\"mean_QSAR\", mean_QSAR1, \" standardar deviation\", st_d_QSAR1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dVFJpwOUcfNX","executionInfo":{"status":"ok","timestamp":1665508826802,"user_tz":360,"elapsed":46848,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"outputId":"6560fd32-8139-44c4-d9e3-a38aeaf7a1fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for breast(test):  [0.5789473684210527, 0.9239766081871345, 0.8713450292397661, 0.9181286549707602, 0.7777777777777778, 0.9415204678362573, 0.8245614035087719, 0.8947368421052632, 0.40350877192982454, 0.5906432748538012]\n","accuracy for QSAR(test):  [0.7066246056782335, 0.6498422712933754, 0.6782334384858044, 0.6214511041009464, 0.668769716088328, 0.694006309148265, 0.668769716088328, 0.6782334384858044, 0.6561514195583596, 0.6656151419558359]\n","ensemble perceptron---------------------------------------------------\n","mean_breast 0.7725146198830409  standardar deviation 0.17517426480458623\n","mean_QSAR 0.6687697160883281  standardar deviation 0.022395254699430732\n"]}]},{"cell_type":"code","source":["X_breast = np.hstack([X_breast, np.ones((len(X_breast), 1))])\n","X_QSAR = np.hstack([X_QSAR, np.ones((len(X_QSAR), 1))])\n","accuracy_test_breast2= []\n","accuracy_test_QSAR2= []\n","for l in range(10):\n","  X_train_breast, X_test_breast, y_train_breast, y_test_breast = train_test_split(\n","    X_breast, y_breast, test_size=0.3, random_state=l)\n","  X_train_QSAR, X_test_QSAR, y_train_QSAR, y_test_QSAR = train_test_split(\n","    X_QSAR, y_QSAR, test_size=0.3, random_state=l)\n","  p3 = perceptron (iterations=10, learning_rate=0.2, \n","                 plot_data=False, random_w=True, seed=42)\n","  p3.fit(X_train_breast,y_train_breast)\n","\n","  y_pred_test_breast = p3.predict(X_test_breast)\n","\n","  p4 = perceptron (iterations=10, learning_rate=0.2, \n","                 plot_data=False, random_w=True, seed=42)\n","  \n","  p4.fit(X_QSAR,y_QSAR)\n","  y_pred_test_QSAR = p4.predict(X_test_QSAR)\n","  accuracy_test_breast2.append(np.mean(y_test_breast == y_pred_test_breast))\n","  accuracy_test_QSAR2.append(np.mean(y_test_QSAR == y_pred_test_QSAR))\n","\n","\n","\n","print('accuracy for breast(test): ', accuracy_test_breast2)\n","print('accuracy for QSAR(test): ', accuracy_test_QSAR2)\n","\n","mean_breast2 = np.mean(accuracy_test_breast2)\n","st_d_breast2 = np.std(accuracy_test_breast2)\n","mean_QSAR2 = np.mean(accuracy_test_QSAR2)\n","st_d_QSAR2 = np.std(accuracy_test_QSAR2)\n","print(\"regular perceptron-------------------------------------------------\")\n","print(\"mean_breast\", mean_breast2, \" standardar deviation\", st_d_breast2)\n","print(\"mean_QSAR\", mean_QSAR2, \" standardar deviation\", st_d_QSAR2)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4j6i-JuTpGp6","executionInfo":{"status":"ok","timestamp":1665508828191,"user_tz":360,"elapsed":1424,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"outputId":"467d41cf-9e29-49a1-b491-39ca6f0223c7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy for breast(test):  [0.9298245614035088, 0.8830409356725146, 0.9064327485380117, 0.9122807017543859, 0.8128654970760234, 0.935672514619883, 0.8011695906432749, 0.8888888888888888, 0.7192982456140351, 0.5730994152046783]\n","accuracy for QSAR(test):  [0.7066246056782335, 0.6498422712933754, 0.6782334384858044, 0.6214511041009464, 0.668769716088328, 0.694006309148265, 0.668769716088328, 0.6782334384858044, 0.6561514195583596, 0.6656151419558359]\n","regular perceptron-------------------------------------------------\n","mean_breast 0.8362573099415205  standardar deviation 0.10909215266770543\n","mean_QSAR 0.6687697160883281  standardar deviation 0.022395254699430732\n"]}]},{"cell_type":"code","source":["data1 = [[0.7847953216374268,0.835672514619883], [0.1778354784785575,0.10872947671821871]]\n","print ('Breast cancer')\n","df1 = pd.DataFrame(data1,columns =[\"ensemble_perceptron\",\"perceptron\"],index = ['Mean', 'Standard deviation'])\n","display(df1)\n","print()\n","data2 = [[0.6694006309148266,0.6687697160883281], [0.022386365929602747,0.022395254699430732]]\n","print ('QSAR')\n","df2 = pd.DataFrame(data2,columns =[\"ensemble_perceptron\",\"perceptron\"],index = ['Mean', 'Standard deviation'])\n","display(df2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":259},"id":"a38O1BQPzDjl","executionInfo":{"status":"ok","timestamp":1665508828192,"user_tz":360,"elapsed":14,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"outputId":"48b640f9-a722-481d-9700-89e48606bacb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Breast cancer\n"]},{"output_type":"display_data","data":{"text/plain":["                    ensemble_perceptron  perceptron\n","Mean                           0.784795    0.835673\n","Standard deviation             0.177835    0.108729"],"text/html":["\n","  <div id=\"df-95c82e62-9344-4cd6-8821-7992c2802bf4\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ensemble_perceptron</th>\n","      <th>perceptron</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Mean</th>\n","      <td>0.784795</td>\n","      <td>0.835673</td>\n","    </tr>\n","    <tr>\n","      <th>Standard deviation</th>\n","      <td>0.177835</td>\n","      <td>0.108729</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-95c82e62-9344-4cd6-8821-7992c2802bf4')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-95c82e62-9344-4cd6-8821-7992c2802bf4 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-95c82e62-9344-4cd6-8821-7992c2802bf4');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","QSAR\n"]},{"output_type":"display_data","data":{"text/plain":["                    ensemble_perceptron  perceptron\n","Mean                           0.669401    0.668770\n","Standard deviation             0.022386    0.022395"],"text/html":["\n","  <div id=\"df-bcb0e620-497a-44dd-ae45-36e4ddc47c16\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ensemble_perceptron</th>\n","      <th>perceptron</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Mean</th>\n","      <td>0.669401</td>\n","      <td>0.668770</td>\n","    </tr>\n","    <tr>\n","      <th>Standard deviation</th>\n","      <td>0.022386</td>\n","      <td>0.022395</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcb0e620-497a-44dd-ae45-36e4ddc47c16')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bcb0e620-497a-44dd-ae45-36e4ddc47c16 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bcb0e620-497a-44dd-ae45-36e4ddc47c16');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"1MHVNGbIErv7"},"source":["## Part 2:  Learning Curves \n","\n","Whenever we train a classifier it is useful to know if we have collected a sufficient amount of data for accurate classification.  A good way of determining that is to construct a **learning curve**, which is a plot of classifier performance as a function of the number of training examples.  Plot a learning curve for the perceptron algorithm using the Gisette dataset.  You can use the Gisette validation set for testing purposes.  The x-axis for the plot (number of training examples) should be on a logarithmic scale - something like 10,20,40,80,200,400,800.  Use numbers that are appropriate for the dataset at hand, choosing values that illustrate the variation that you observe.  What can you conclude from the learning curve you have constructed for this particular dataset?\n","In answering this question, you can use the following [wikipedia article](https://en.wikipedia.org/wiki/Learning_curve#In_machine_learning).\n","Make sure that you use a fixed test set to evaluate performance while varying the size of the training set.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxEazc7FErv8","executionInfo":{"status":"ok","timestamp":1665508834058,"user_tz":360,"elapsed":5872,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7c2760e1-52d5-47b7-af63-e1860c448773"},"outputs":[{"output_type":"stream","name":"stdout","text":["(6000, 5000)\n","(6000,)\n","(1000, 5000)\n","(1000,)\n"]}],"source":["###########train_data###################\n","train_data = []\n","file1 = open('gisette_train.data','r')\n","for line in file1.readlines():\n","  train_data.append((line.strip()).split(' '))\n","\n","train_data = np.array(train_data, dtype = np.float32)\n","print(train_data.shape)\n","\n","###########train_labels###################\n","train_labels = []\n","file2 = open('gisette_train.labels','r')\n","for line in file2.readlines():\n","  train_labels.append((line.strip()).split(' '))\n","train_labels = np.array(train_labels, dtype = np.float32).flatten()\n","print(train_labels.shape)\n","\n","###########valid.data###################\n","valid_data = []\n","file3 = open('gisette_valid.data','r')\n","for line in file3.readlines():\n","  valid_data.append((line.strip()).split(' '))\n","\n","valid_data = np.array(valid_data, dtype = np.float32)\n","print(valid_data.shape)\n","\n","###########valid_labels###################\n","valid_labels = []\n","file4 = open('gisette_valid.labels','r')\n","for line in file4.readlines():\n","  valid_labels.append((line.strip()).split(' '))\n","valid_labels = np.array(valid_labels, dtype = np.float32).flatten()\n","print(valid_labels.shape)\n"]},{"cell_type":"code","source":["training_example = [10,20,40,80,200,400,800,1600]\n","accuracy1 = []\n","accuracy2 = []\n","for n in training_example:\n","  p = perceptron()\n","  p.fit(train_data[:n,], train_labels[:n])\n","  p2.fit(valid_data[:n,], valid_labels[:n])\n","  y_pred1 = p.predict(valid_data[:n,])\n","  y_pred2 = p2.predict(train_data[:n,])\n","  accuracy1.append(np.mean(valid_labels[:n] == y_pred1[:n]))\n","  accuracy2.append(np.mean(train_labels[:n] == y_pred2[:n]))\n","print(accuracy1)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k9IebHP-yMHB","executionInfo":{"status":"ok","timestamp":1665508958786,"user_tz":360,"elapsed":20239,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"outputId":"77bca94d-e7b0-46c3-c43d-04040d956dab"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["converged in 3 iterations \n","converged in 3 iterations \n","converged in 5 iterations \n","converged in 5 iterations \n","converged in 5 iterations \n","converged in 5 iterations \n","converged in 6 iterations \n","converged in 4 iterations \n","converged in 7 iterations \n","converged in 5 iterations \n","converged in 7 iterations \n","converged in 6 iterations \n","converged in 9 iterations \n","converged in 9 iterations \n","converged in 12 iterations \n","converged in 8 iterations \n","[0.5, 0.8, 0.825, 0.8375, 0.91, 0.905, 0.95125, 0.963]\n"]}]},{"cell_type":"code","source":["print(accuracy1, accuracy2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5vzR6mSWBg-i","executionInfo":{"status":"ok","timestamp":1665508843900,"user_tz":360,"elapsed":15,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"outputId":"2dc41ee1-06aa-4ff8-f6d5-dd8eec292a4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.5, 0.8, 0.825, 0.8375, 0.91, 0.905, 0.95125, 0.963] [0.4, 0.65, 0.7, 0.8375, 0.905, 0.92, 0.93625, 0.94875]\n"]}]},{"cell_type":"code","source":["plt.semilogy(training_example,accuracy1, label = \"Valid data\",marker = 'o')\n","plt.semilogy(training_example,accuracy2, label = \"Train data\", marker = 'o')\n","plt.xlabel(\"Number of training example\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend();"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":284},"id":"l3ZFu-NX1ZMR","executionInfo":{"status":"ok","timestamp":1665508971158,"user_tz":360,"elapsed":654,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"outputId":"aa7f3cb6-fbb0-4e36-9b45-7f996e6f0ee8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"YX53C9hKErv9"},"source":["\n","Based on the graph, I can noticed that the error of train data and valid data  are very small."]},{"cell_type":"markdown","metadata":{"id":"a7g9rNyYErv-"},"source":["## Part 3:  Data standardization \n","\n","In this section we will explore the effect of normalizing the data, focusing on normalization of each feature individually.  In class we saw how to convert each column (i.e. feature) of a data matrix so that it fall in the range $[-1,1]$.  In this assignment we will explore a different approach callled **standardization**.\n","\n","Here's what you need to do:\n","\n","* Write a method to standardize a data matrix, so that each column has zero mean and standard deviation equal to 1.  This is done by subtracting the mean of each column, and dividing by its standard deviation.  See details [here](https://en.wikipedia.org/wiki/Feature_scaling#Standardization_(Z-score_Normalization)).  \n","Do not use the scikit-learn implementation.\n","\n","* Compare the accuracy of the standard perceptron on the heart dataset  with standardization and without it.  Which leads to better performance?  Can you explain why?\n","\n","\n","In this exercise we're using the\n","[Heart disease diagnosis dataset](http://archive.ics.uci.edu/ml/datasets/Heart+Disease).\n","This dataset has several data files associated with it.  The easiest would be to use [this file](http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data), where categorical variables have been replaced with numerical vaues.  The last column in the file contains the label associated with each example.  In the processed file, a label `0` corresponds to a healthy individual; other values correspond to varying levels of heart disease.  **In your experiments focus on the binary classification problem of trying to distinguish between healthy and non-healthy individuals.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gJbLRSmTErv_","executionInfo":{"status":"ok","timestamp":1665508844707,"user_tz":360,"elapsed":213,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"06771ab6-4dc0-46ce-cd95-88127962be1f"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[63.  1.  1. ...  3.  0.  6.]\n"," [67.  1.  4. ...  2.  3.  3.]\n"," [67.  1.  4. ...  2.  2.  7.]\n"," ...\n"," [57.  1.  4. ...  2.  1.  7.]\n"," [57.  0.  2. ...  2.  1.  3.]\n"," [38.  1.  3. ...  1.  0.  3.]]\n"]}],"source":["heart_disease = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data', header = None)\n","X_heart = heart_disease.values[:,:-1]\n","y_heart = heart_disease.values[:,-1]\n","# print(X_heart.shape,y_heart.shape)\n","# print(y_heart)\n","# 1 is health individual, -1 is non-health individual\n","X_heart[X_heart == '?']=0\n","y_heart[y_heart>0] = -1\n","y_heart[y_heart==0]=1\n","y_heart[y_heart== '?']=0\n","X_heart = np.array(X_heart,dtype=np.float32)\n","y_heart = np.array(y_heart,dtype=np.float32)\n","\n","# print(X_heart.shape, y_heart.shape)\n","print(X_heart)\n"]},{"cell_type":"code","source":["# x' = (x - x(avg))/standard deviation\n","from sklearn import preprocessing\n","\n","def standardization(x):\n","  return (x - np.mean(x, axis=0)) / np.std(x, axis=0)\n","\n","X_heart_std =standardization(X_heart)\n","#y_heart_std =standardization(y_heart)\n","\n"],"metadata":{"id":"2MJSyrhq3y0i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["p = perceptron(iterations = 10, learning_rate = 0.1)\n","X_train1, X_test1, y_train1, y_test1 = train_test_split(X_heart, y_heart, test_size=0.3, random_state=5)\n","p.fit(X_train1,y_train1)\n","y_pred_test1 = p.predict(X_test1)\n","y_pred_train1 = p.predict(X_train1) \n","accuracy_test_heart1 = np.mean(y_test1 == y_pred_test1) \n","accuracy_train_heart1 = np.mean(y_train1 == y_pred_train1)\n","print(\"accuarcy of data without standardization\",accuracy_test_heart1, accuracy_train_heart1)\n","\n","p = perceptron(iterations = 10, learning_rate = 0.1)\n","X_train2, X_test2, y_train2, y_test2 = train_test_split(X_heart_std, y_heart, test_size=0.3, random_state=5)\n","p.fit(X_train2,y_train2)\n","y_pred_test2 = p.predict(X_test2)\n","y_pred_train2 = p.predict(X_train2) \n","accuracy_test_heart2 = np.mean(y_test2 == y_pred_test2) \n","accuracy_train_heart2 = np.mean(y_train2== y_pred_train2)\n","\n","print(\"accuracy of data with standardization\",accuracy_test_heart2, accuracy_train_heart2)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ThHVvD-X3-I5","executionInfo":{"status":"ok","timestamp":1665508844708,"user_tz":360,"elapsed":5,"user":{"displayName":"Thea Zhu","userId":"02046604984351624783"}},"outputId":"757c5be2-b82f-4919-f62c-b167eed7b867"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["accuarcy of data without standardization 0.4175824175824176 0.47641509433962265\n","accuracy of data with standardization 0.7362637362637363 0.7216981132075472\n"]}]},{"cell_type":"markdown","metadata":{"id":"PXPFM6vOErwA"},"source":["*discussion and explanation*\n","Which leads to better performance? Can you explain why?\n","\n","the data with standardization leads to better ferformace. the way of feature scaling is to normalize the features of data which make it easily to compare the result. meanwhile, the data is standardized, the program's runtime will be faster comparing with data without standarization."]},{"cell_type":"markdown","metadata":{"id":"lABQs0CKErwB"},"source":["### Your Report\n","\n","Answer the questions in the cells reserved for that purpose.\n","\n","\n","### Submission\n","\n","Submit your report as a Jupyter notebook via Canvas.  Running the notebook should generate all the plots in your notebook.\n","\n","### Grading \n","\n","Although we will not grade on a 100 pt scale, the following is a grading sheet that will help you:\n","\n","```\n","Grading sheet for assignment 2\n","\n","Part 1:  60 points.\n","Part 2:  20 points.\n","Part 3:  20 points.\n","```\n","\n","Grading will be based on the following criteria:\n","\n","  * Code correctness.\n","  * Plots and other results are well formatted and easy to understand.\n","  * Interesting and meaningful observations made where requested.\n","  * Notebook is readable, well-organized, and concise."]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}